{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "%matplotlib inline \n",
    "\n",
    "df = pd.read_csv('world-atlas-of-language-structures/language.csv')\n",
    "\n",
    "list_of_names = df.loc[:,'Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Looking at number of languags in each language family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# group families by number of langs in each\n",
    "langs_per_fam = df.groupby('family')['Name'].count()\n",
    "\n",
    "# number of langs in each family - might be a good idea to list ones that are > 1 separately \n",
    "langs_minus_one = []\n",
    "\n",
    "for langs in langs_per_fam:\n",
    "    if langs > 1:\n",
    "        langs_minus_one.append(langs)\n",
    "\n",
    "# 2 boxplots to show extra large or extra small language families\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.boxplot(langs_per_fam, showbox=True)\n",
    "plt.ylabel('Languages per family')\n",
    "plt.title('Relative Sizes of Language Families')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(langs_minus_one, showbox=True)\n",
    "plt.title('Only counting families > 1 language')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These boxplots show the concentration of languages in each language family included in this dataset. In the first plot, all of the languages and families are counted, and in the second, only the language families that consisted of more than 1 language are included. The graph highlights the size of the 1 or 2 largest language families compared to the other smaller, or perhaps less researched / less well-known, families. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Comparing tone complexity with syllable structure complexity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table = df.loc[:,['Name', 'family','macroarea','3A Consonant-Vowel Ratio','12A Syllable Structure', '13A Tone']]\n",
    "\n",
    "# first getting the tone data\n",
    "tonal_complexity = new_table.loc[:,'13A Tone']\n",
    "\n",
    "# create an empty list where you can put the data after cleaning it up\n",
    "numeric_tc = []\n",
    "\n",
    "# clean up the data from the column and populate the empty list with integers \n",
    "for tone in tonal_complexity:\n",
    "    if pd.isna(tone):\n",
    "         numeric_tc.append(0)\n",
    "    else:\n",
    "         numeric_tc.append(int(tone[0]))\n",
    "\n",
    "# then basically the same thing for syllable structure complexity\n",
    "ss_complexity = new_table.loc[:,'12A Syllable Structure']\n",
    "\n",
    "numeric_ssc = []\n",
    "\n",
    "for sylst in ss_complexity:\n",
    "    if pd.isna(sylst):\n",
    "         numeric_ssc.append(0)\n",
    "    else:\n",
    "         numeric_ssc.append(int(sylst[0]))\n",
    "            \n",
    "# create the data frame for the two lists\n",
    "\n",
    "dframe = pd.DataFrame(index=[list_of_names])\n",
    "dframe['tonal complexity'] = numeric_tc \n",
    "dframe['syllable structure'] = numeric_ssc\n",
    "\n",
    "# get rid of any rows that have 0, because without both variables, there's no way to compare\n",
    "no_zero_tones = dframe.loc[lambda df: dframe['tonal complexity'] >= 1, ['tonal complexity', 'syllable structure']]\n",
    "no_zeroes = no_zero_tones.loc[lambda df: no_zero_tones['syllable structure'] >= 1, ['tonal complexity', 'syllable structure']]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(\n",
    "    x=no_zeroes['syllable structure'],\n",
    "    y=no_zeroes['tonal complexity'],\n",
    "    color='green', alpha=.15\n",
    ")\n",
    "plt.xlabel('syllable strcture complexity')\n",
    "plt.ylabel('tone complexity')\n",
    "plt.title('Syllable struture complexity compared to tonal complexity')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(numeric_tc, normed=True, color='blue', alpha=.5) \n",
    "plt.hist(numeric_ssc, normed=True, color='red', alpha=.3)\n",
    "plt.xlabel('Blue = tonal, red = syllable')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was curious to see if there was any correlation betweeen syllable structure complexity and tone complexity, both of which are on scales from 1 (low / none) - 3 (most complex). First I tried a scatter plot, which doesn't seem to show any specific trend. It could also be that this graph type wasn't the best for this kind of comparison. Because of this, I tried to plot the data on a histogram. It looks like, though there are more tonal languages that have less complex syllable structure, languages without tones follow the same pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Looking at the number of languages and their locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the longitude\n",
    "lang_long = df.loc[:,'longitude']\n",
    "\n",
    "rounded_long = []\n",
    "for tude in lang_long:\n",
    "        rounded_long.append(round(tude,2))\n",
    "\n",
    "#get the latitude\n",
    "lang_lat = df.loc[:,'latitude']\n",
    "\n",
    "rounded_lat = []\n",
    "for tude in lang_lat:\n",
    "    rounded_lat.append(round(tude,2))\n",
    "\n",
    "# make the DF\n",
    "\n",
    "langmap = pd.DataFrame(index=[list_of_names])\n",
    "langmap['longitude'] = rounded_long\n",
    "langmap['latitude'] = rounded_lat\n",
    "\n",
    "#print (langmap)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(\n",
    "    x=langmap['longitude'],\n",
    "    y=langmap['latitude'],\n",
    "    color='purple', alpha=.2\n",
    ")\n",
    "plt.title('Language density across the world')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a scatter plot showing number of languages based on their geographical location of origin, using rounded coordinates. Because of the opacity setting, more languages are from darker regions, and less languages are from the lighter regions. (The number of speakers of each language is not included in this dataset, so some of them might no longer be (commonly) spoken.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Comparing Inclusive/Exclusive Distinction in Independent Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# possible results\n",
    "# 1 No 'we'\n",
    "# 2 'We' the same as 'I'\n",
    "# 3 No inclusive/exclusive\n",
    "# 4 Only inclusive\n",
    "# 5 Inclusive/exclusive\n",
    "\n",
    "# formatting the data so its all integers\n",
    "\n",
    "testing = df.groupby(['39A Inclusive/Exclusive Distinction in Independent Pronouns'])['Name'].count()\n",
    "# print(testing)\n",
    "\n",
    "labelled = [ \"No 'we'\",\"'We' the same as 'I'\", \"No inclusive/exclusive\", \"Only inclusive\", \"Inclusive/exclusive\"]\n",
    "\n",
    "plt.pie(testing, shadow=True, startangle=20, explode=(0.27, 0.22, 0.07, 0.07, 0.07), labels=labelled)\n",
    "plt.title('Prevalance of inclusive/exclusive distinction in independent pronouns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pie chart shows the currently existing ways languages either distinguish, or don't, inclusiveness / exclusivness via independent pronouns, and the prevalance of each method. It looks like distinguishing is a bit less common than failing to distinguish between the two options, but there were also other ways languages handled this linguistic ambiguity. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
