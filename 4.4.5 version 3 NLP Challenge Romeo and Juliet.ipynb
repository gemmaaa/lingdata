{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4.5 NLP Challenge using Romeo and Juliet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import shakespeare, stopwords #,  qc\n",
    "\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 . Data processing, cleaning, language parsing\n",
    "\n",
    "First, taking a look at documents in shakespeare, and picking one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a_and_c.xml', 'dream.xml', 'hamlet.xml', 'j_caesar.xml', 'macbeth.xml', 'merchant.xml', 'othello.xml', 'r_and_j.xml']\n"
     ]
    }
   ],
   "source": [
    "print(shakespeare.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\"?>\r\n",
      "<?xml-stylesheet type=\"text/css\" href=\"shakes.css\"?>\r\n",
      "<!-- <!DOCTYPE PLAY SYSTEM \"play.dtd\"> -->\r\n",
      "\r\n",
      "<PLAY>\r\n",
      "<TITLE>The Tragedy \n"
     ]
    }
   ],
   "source": [
    "rj = shakespeare.raw('r_and_j.xml')\n",
    "print(rj[:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally I didn't know aout XML Element tree so I tried using a lot of regular expressions - a useful explanation of the specific regular expression used is [here](https://stackoverflow.com/questions/8784396/delete-the-words-between-two-delimiters-in-python) (for future reference).\n",
    "\n",
    "However, then I found out about ElementTree, and learned a tiny bit about parsing with it. Here are some tutorials that I am still looking at: [this one from effbott](http://effbot.org/zone/element.htm), and [the python docs](https://docs.python.org/3.5/library/xml.etree.elementtree.html), [datacamp](https://www.datacamp.com/community/tutorials/python-xml-elementtree), [nltk](https://www.nltk.org/book/ch11.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse('/Users/gemma/nltk_data/corpora/shakespeare/r_and_j.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the categories of elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACT',\n",
       " 'FM',\n",
       " 'GRPDESCR',\n",
       " 'LINE',\n",
       " 'P',\n",
       " 'PERSONA',\n",
       " 'PERSONAE',\n",
       " 'PGROUP',\n",
       " 'PLAY',\n",
       " 'PLAYSUBT',\n",
       " 'PROLOGUE',\n",
       " 'SCENE',\n",
       " 'SCNDESCR',\n",
       " 'SPEAKER',\n",
       " 'SPEECH',\n",
       " 'STAGEDIR',\n",
       " 'TITLE'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([elem.tag for elem in root.iter()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaining an understanding of the structure of the document / tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parent_map = dict((c, p) for p in tree.getiterator() for c in p)\n",
    "\n",
    "#for key in parent_map:\n",
    "#    if key.text:\n",
    "#        print(\"key tag:  \", key.tag, \" key text: \", key.text, \" parent tag: \", parent_map[key].tag, \" parent text: \", \n",
    "#             parent_map[key].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will extract the elements of interest and put them in a dataframe.\n",
    "\n",
    "At the same time, I'll clean up the lines using the below function, as we go, for the sake of efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACT I\n",
      "SCENE I.  Verona. A public place.\n",
      "SCENE II.  A street.\n",
      "SCENE III.  A room in Capulet's house.\n",
      "SCENE IV.  A street.\n",
      "SCENE V.  A hall in Capulet's house.\n",
      "ACT II\n",
      "SCENE I.  A lane by the wall of Capulet's orchard.\n",
      "SCENE II.  Capulet's orchard.\n",
      "SCENE III.  Friar Laurence's cell.\n",
      "SCENE IV.  A street.\n",
      "SCENE V.  Capulet's orchard.\n",
      "SCENE VI.  Friar Laurence's cell.\n",
      "ACT III\n",
      "SCENE I.  A public place.\n",
      "SCENE II.  Capulet's orchard.\n",
      "SCENE III.  Friar Laurence's cell.\n",
      "SCENE IV.  A room in Capulet's house.\n",
      "SCENE V.  Capulet's orchard.\n",
      "ACT IV\n",
      "SCENE I.  Friar Laurence's cell.\n",
      "SCENE II.  Hall in Capulet's house.\n",
      "SCENE III.  Juliet's chamber.\n",
      "SCENE IV.  Hall in Capulet's house.\n",
      "SCENE V.  Juliet's chamber.\n",
      "ACT V\n",
      "SCENE I.  Mantua. A street.\n",
      "SCENE II.  Friar Laurence's cell.\n",
      "SCENE III.  A churchyard; in it a tomb belonging to the Capulets.\n"
     ]
    }
   ],
   "source": [
    "# trying to get all of the speakers and their lines in an array\n",
    "\n",
    "rows = {}\n",
    "\n",
    "l = 0 \n",
    "\n",
    "for i, act in enumerate(root.findall('ACT')):\n",
    "    for s, act_t in enumerate(act.findall('TITLE')):\n",
    "        print(act_t.text)\n",
    "    for j, scene in enumerate(act.findall('SCENE')):\n",
    "        for q, scene_t in enumerate(scene.findall('TITLE')):\n",
    "            print(scene_t.text)\n",
    "            only_number = scene_t.text.split('.',1)\n",
    "        for k, speech in enumerate(scene.findall('SPEECH')):\n",
    "            for i, speaker in enumerate(speech.findall('SPEAKER')):\n",
    "                \n",
    "                # there is an instance of LADY  CAPULET which shouldbe LADY CAPULET\n",
    "                if speaker.text == 'LADY  CAPULET':\n",
    "                    speaker.text = speaker.text.replace('LADY  CAPULET', 'LADY CAPULET')\n",
    "                \n",
    "                all_lines = []\n",
    "                for line in speech.findall('LINE'):\n",
    "                    if line.text:\n",
    "                        line.text = text_cleaner(line.text)\n",
    "                        all_lines.append(line.text)\n",
    "                \n",
    "                rows[l] = ([act_t.text, only_number[0], only_number[1], speaker.text, ' '.join(all_lines)])\n",
    "                l+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>Scene</th>\n",
       "      <th>Scene_Name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>Gregory, o' my word, we'll not carry coals.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>No, for then we should be colliers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I mean, an we be in choler, we'll draw.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>Ay, while you live, draw your neck out o' the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I strike quickly, being moved.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Act    Scene                 Scene_Name  Speaker  \\\n",
       "0  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "1  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "2  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "3  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "4  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "\n",
       "                                                Line  \n",
       "0        Gregory, o' my word, we'll not carry coals.  \n",
       "1                No, for then we should be colliers.  \n",
       "2            I mean, an we be in choler, we'll draw.  \n",
       "3  Ay, while you live, draw your neck out o' the ...  \n",
       "4                     I strike quickly, being moved.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(data=rows, orient='index', columns=['Act', 'Scene', 'Scene_Name','Speaker', 'Line'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's parse the lines in a new column with spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      ",\n",
      "for\n",
      "then\n",
      "-PRON-\n",
      "should\n",
      "be\n",
      "collier\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# first let me make sure this will work\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "testing = nlp(df.loc[1, 'Line'])\n",
    "\n",
    "for token in testing:\n",
    "    print(token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it worked! let's apply it to the whole dataframe of lines\n",
    "\n",
    "df['parsed'] = df['Line'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>Scene</th>\n",
       "      <th>Scene_Name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Line</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>Gregory, o' my word, we'll not carry coals.</td>\n",
       "      <td>(Gregory, ,, o, ', my, word, ,, we, 'll, not, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>No, for then we should be colliers.</td>\n",
       "      <td>(No, ,, for, then, we, should, be, colliers, .)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I mean, an we be in choler, we'll draw.</td>\n",
       "      <td>(I, mean, ,, an, we, be, in, choler, ,, we, 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>Ay, while you live, draw your neck out o' the ...</td>\n",
       "      <td>(Ay, ,, while, you, live, ,, draw, your, neck,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I strike quickly, being moved.</td>\n",
       "      <td>(I, strike, quickly, ,, being, moved, .)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Act    Scene                 Scene_Name  Speaker  \\\n",
       "0  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "1  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "2  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "3  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "4  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "\n",
       "                                                Line  \\\n",
       "0        Gregory, o' my word, we'll not carry coals.   \n",
       "1                No, for then we should be colliers.   \n",
       "2            I mean, an we be in choler, we'll draw.   \n",
       "3  Ay, while you live, draw your neck out o' the ...   \n",
       "4                     I strike quickly, being moved.   \n",
       "\n",
       "                                              parsed  \n",
       "0  (Gregory, ,, o, ', my, word, ,, we, 'll, not, ...  \n",
       "1    (No, ,, for, then, we, should, be, colliers, .)  \n",
       "2  (I, mean, ,, an, we, be, in, choler, ,, we, 'l...  \n",
       "3  (Ay, ,, while, you, live, ,, draw, your, neck,...  \n",
       "4           (I, strike, quickly, ,, being, moved, .)  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>Scene</th>\n",
       "      <th>Scene_Name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Line</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Act, Scene, Scene_Name, Speaker, Line, parsed]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double checking that LADY  CAPULET was replaced w correctly spaced name\n",
    "df[df['Speaker'] == 'LADY  CAPULET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating features using two different NLP methods, BOW and tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. BOW**\n",
    "\n",
    "In order to get a list of the common words from the text, first I'm going to put all the lines together into one text (one string) and then run spaCy on the resulting text. This is a little redundant since I already ran spaCy on each individual line, but it is the best way I could think of to keep the lines organized by speaker in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_lines = []\n",
    "\n",
    "# just look at \"LINE\"s in the tree\n",
    "for line in root.iter('LINE'):\n",
    "    # make sure it's a string (ignore the \"None\" entries)\n",
    "    if isinstance(line.text, str):\n",
    "        all_the_lines.append(line.text)\n",
    "    \n",
    "complete_doc = nlp((' '.join(all_the_lines)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I'll use the bag of words function to get the most common words across all of the lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = bag_of_words(complete_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the common words as word counts in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_features(original_df, common_words):\n",
    "    \n",
    "    # copy the dataframe so your bow features will be in a new one and wont affect the original data\n",
    "    df = original_df.copy(deep=True)\n",
    "    \n",
    "    # Add the words to the dataframe and set all counts to 0\n",
    "    for word in common_words:\n",
    "        df[word] = 0\n",
    "        \n",
    "    # Process each row, counting the occurrence of words in each parsed sentence.\n",
    "    for i, sentence in enumerate(df['parsed']):\n",
    "        \n",
    "        # I already converted the sentence to lemmas, and filtered out punctuation and stop words.\n",
    "        # Now I'm just going to get a list of the words in each line that are in the common words list.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if token.lemma_ in common_words\n",
    "                ]\n",
    "        \n",
    "        # Populate the row with word counts\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n"
     ]
    }
   ],
   "source": [
    "df_plus_bow = bow_features(df,common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>Scene</th>\n",
       "      <th>Scene_Name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Line</th>\n",
       "      <th>parsed</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>be</th>\n",
       "      <th>and</th>\n",
       "      <th>the</th>\n",
       "      <th>...</th>\n",
       "      <th>hatred</th>\n",
       "      <th>intercession</th>\n",
       "      <th>stead</th>\n",
       "      <th>plain</th>\n",
       "      <th>homely</th>\n",
       "      <th>plainly</th>\n",
       "      <th>woo'd</th>\n",
       "      <th>forsake</th>\n",
       "      <th>maria</th>\n",
       "      <th>brine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>Gregory, o' my word, we'll not carry coals.</td>\n",
       "      <td>(Gregory, ,, o, ', my, word, ,, we, 'll, not, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>No, for then we should be colliers.</td>\n",
       "      <td>(No, ,, for, then, we, should, be, colliers, .)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I mean, an we be in choler, we'll draw.</td>\n",
       "      <td>(I, mean, ,, an, we, be, in, choler, ,, we, 'l...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>Ay, while you live, draw your neck out o' the ...</td>\n",
       "      <td>(Ay, ,, while, you, live, ,, draw, your, neck,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I strike quickly, being moved.</td>\n",
       "      <td>(I, strike, quickly, ,, being, moved, .)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2006 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Act    Scene                 Scene_Name  Speaker  \\\n",
       "0  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "1  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "2  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "3  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "4  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "\n",
       "                                                Line  \\\n",
       "0        Gregory, o' my word, we'll not carry coals.   \n",
       "1                No, for then we should be colliers.   \n",
       "2            I mean, an we be in choler, we'll draw.   \n",
       "3  Ay, while you live, draw your neck out o' the ...   \n",
       "4                     I strike quickly, being moved.   \n",
       "\n",
       "                                              parsed  -PRON-  be  and  the  \\\n",
       "0  (Gregory, ,, o, ', my, word, ,, we, 'll, not, ...       2   0    0    0   \n",
       "1    (No, ,, for, then, we, should, be, colliers, .)       1   1    0    0   \n",
       "2  (I, mean, ,, an, we, be, in, choler, ,, we, 'l...       3   1    0    0   \n",
       "3  (Ay, ,, while, you, live, ,, draw, your, neck,...       2   0    0    1   \n",
       "4           (I, strike, quickly, ,, being, moved, .)       1   1    0    0   \n",
       "\n",
       "   ...    hatred  intercession  stead  plain  homely  plainly  woo'd  forsake  \\\n",
       "0  ...         0             0      0      0       0        0      0        0   \n",
       "1  ...         0             0      0      0       0        0      0        0   \n",
       "2  ...         0             0      0      0       0        0      0        0   \n",
       "3  ...         0             0      0      0       0        0      0        0   \n",
       "4  ...         0             0      0      0       0        0      0        0   \n",
       "\n",
       "   maria  brine  \n",
       "0      0      0  \n",
       "1      0      0  \n",
       "2      0      0  \n",
       "3      0      0  \n",
       "4      0      0  \n",
       "\n",
       "[5 rows x 2006 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plus_bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the bow features in a model soon, but first I'll create the features using df-idf.\n",
    "\n",
    "**b. df-idf**\n",
    "\n",
    "Let's take a look at the dataframe again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>Scene</th>\n",
       "      <th>Scene_Name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Line</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>Gregory, o' my word, we'll not carry coals.</td>\n",
       "      <td>(Gregory, ,, o, ', my, word, ,, we, 'll, not, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>No, for then we should be colliers.</td>\n",
       "      <td>(No, ,, for, then, we, should, be, colliers, .)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I mean, an we be in choler, we'll draw.</td>\n",
       "      <td>(I, mean, ,, an, we, be, in, choler, ,, we, 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>Ay, while you live, draw your neck out o' the ...</td>\n",
       "      <td>(Ay, ,, while, you, live, ,, draw, your, neck,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I strike quickly, being moved.</td>\n",
       "      <td>(I, strike, quickly, ,, being, moved, .)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Act    Scene                 Scene_Name  Speaker  \\\n",
       "0  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "1  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "2  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "3  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "4  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "\n",
       "                                                Line  \\\n",
       "0        Gregory, o' my word, we'll not carry coals.   \n",
       "1                No, for then we should be colliers.   \n",
       "2            I mean, an we be in choler, we'll draw.   \n",
       "3  Ay, while you live, draw your neck out o' the ...   \n",
       "4                     I strike quickly, being moved.   \n",
       "\n",
       "                                              parsed  \n",
       "0  (Gregory, ,, o, ', my, word, ,, we, 'll, not, ...  \n",
       "1    (No, ,, for, then, we, should, be, colliers, .)  \n",
       "2  (I, mean, ,, an, we, be, in, choler, ,, we, 'l...  \n",
       "3  (Ay, ,, while, you, live, ,, draw, your, neck,...  \n",
       "4           (I, strike, quickly, ,, being, moved, .)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks ready to run the model, so let's go to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Supervised learning models\n",
    "\n",
    "Using the different sets of features from above. First let's use bow with random forest and see if we can predict the speaker.\n",
    "\n",
    "a. **BOW** \n",
    "\n",
    "<em>i. with Random Forest</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9840954274353877\n",
      "\n",
      "Test set score: 0.17261904761904762\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = df_plus_bow['Speaker']\n",
    "X = df_plus_bow.drop(['Act','Scene', 'Scene_Name','Speaker', 'Line', 'parsed'], 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "validate = cross_val_score(rfc, X_test, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The warning shows a problem with the number of members in each class, meaning in this case the number of lines for some of the speakers. Let's see if we can drop speakers with less than a certain threshold of lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the counts of each speaker and add it as a column\n",
    "df_plus_bow['Speaker_counts'] = df_plus_bow.groupby('Speaker')['Line'].transform('count')\n",
    "\n",
    "# drop lines whose speakers have less than 10 lines from the rows\n",
    "df_plus_bow_max = df_plus_bow.drop(df_plus_bow[df_plus_bow.Speaker_counts < 10].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Speaker\n",
       "ROMEO             163\n",
       "JULIET            118\n",
       "Nurse              89\n",
       "BENVOLIO           64\n",
       "MERCUTIO           62\n",
       "FRIAR LAURENCE     55\n",
       "CAPULET            50\n",
       "LADY CAPULET       45\n",
       "PARIS              23\n",
       "SAMPSON            20\n",
       "TYBALT             17\n",
       "PRINCE             16\n",
       "GREGORY            15\n",
       "PETER              13\n",
       "BALTHASAR          12\n",
       "Servant            10\n",
       "MONTAGUE           10\n",
       "Name: Speaker_counts, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check it worked \n",
    "df_plus_bow_max.groupby('Speaker')['Speaker_counts'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9850746268656716\n",
      "\n",
      "Test set score: 0.19169329073482427\n"
     ]
    }
   ],
   "source": [
    "# re run rfc\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y_max = df_plus_bow_max['Speaker']\n",
    "X_max = df_plus_bow_max.drop(['Act','Scene', 'Scene_Name','Speaker', 'Line', 'parsed', 'Speaker_counts'], 1)\n",
    "\n",
    "X_train_max, X_test_max, y_train_max, y_test_max = train_test_split(X_max, \n",
    "                                                    Y_max,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train_max, y_train_max)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train_max, y_train_max))\n",
    "print('\\nTest set score:', rfc.score(X_test_max, y_test_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate = cross_val_score(rfc, X_train_max, y_train_max, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2038835  0.17708333 0.15957447 0.15909091 0.18181818]\n",
      "0.17629007749463232 +/- 0.033079406060104434\n"
     ]
    }
   ],
   "source": [
    "print(validate)\n",
    "print(np.mean(validate), '+/-', np.std(validate)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.18 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (validate.mean(), validate.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>ii. with Logistic Regression</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(503, 2000) (503,)\n",
      "Training set score: 0.9502982107355865\n",
      "\n",
      "Test set score: 0.23809523809523808\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_lr = cross_val_score(lr, X_train_max, y_train_max, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.27 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (validate_lr.mean(), validate_lr.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>iii. with Gradient Boosting</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9701789264413518\n",
      "\n",
      "Test set score: 0.24404761904761904\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_gb = cross_val_score(clf,X_train_max,y_train_max,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (validate_gb.mean(), validate_gb.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. tf-idf**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll run the tf-idf vectorizer to get the vectors for each line. Normally this is on a paragraph basis but since this is a play lines should be a good substitute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_test = train_test_split(df['Line'], test_size=0.4, random_state=0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.75, # drop words that occur in more than 75 percent of the paragraphs\n",
    "                             min_df=3, # only use words that appear at least 3 times\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case \n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "#Applying the vectorizer\n",
    "lines_tfidf=vectorizer.fit_transform(df['Line'])\n",
    "print(\"Number of features: %d\" % lines_tfidf.get_shape()[1])\n",
    "\n",
    "# inititally tried model with parameters: max_df 0.75, min_df 10, # of features was 187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: Gregory, o' my word, we'll not carry coals.\n",
      "Tf_idf vector: {'laurence': 0.41324507177540226, 'friar': 0.336058721652412, 'gone': 0.6486787186462298, 'daughter': 0.3673003861933039, 'time': 0.31424202170388116, 'shall': 0.2486993050410113}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#splitting into training and test sets\n",
    "X_train_tfidf, X_test_tfidf= train_test_split(lines_tfidf, test_size=0.4, random_state=0)\n",
    "\n",
    "#Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "\n",
    "#number of paragraphs\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "#A list of dictionaries, one per paragraph\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n",
    "#List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "#for each paragraph, lists the feature words and their tf-idf scores\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
    "\n",
    "#Keep in mind that the log base 2 of 1 is 0, so a tf-idf score of 0 indicates that the word was\n",
    "# present once in that sentence.\n",
    "print('Original sentence:', X_train[0])\n",
    "print('Tf_idf vector:', tfidf_bypara[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>Dimension reduction</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 98.96534125594387\n",
      "Component 0:\n",
      "Line\n",
      "Thou know'st the mask of night is on my face, Else would a maiden blush bepaint my cheek For that which thou hast heard me speak to-night Fain would I dwell on form, fain, fain deny What I have spoke: but farewell compliment! Dost thou love me? I know thou wilt say 'Ay,' And I will take thy word: yet if thou swear'st, Thou mayst prove false; at lovers' perjuries Then say, Jove laughs. O gentle Romeo, If thou dost love, pronounce it faithfully: Or if thou think'st I am too quickly won, I'll frown and be perverse an say thee nay, So thou wilt woo; but else, not for the world. In truth, fair Montague, I am too fond, And therefore thou mayst think my 'havior light: But trust me, gentleman, I'll prove more true Than those that have more cunning to be strange. I should have been more strange, I must confess, But that thou overheard'st, ere I was ware, My true love's passion: therefore pardon me, And not impute this yielding to light love, Which the dark night hath so discovered.    0.522283\n",
      "Thou canst not speak of that thou dost not feel: Wert thou as young as I, Juliet thy love, An hour but married, Tybalt murdered, Doting like me and like me banished, Then mightst thou speak, then mightst thou tear thy hair, And fall upon the ground, as I do now, Taking the measure of an unmade grave.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  0.428887\n",
      "O Romeo, Romeo! wherefore art thou Romeo? Deny thy father and refuse thy name; Or, if thou wilt not, be but sworn my love, And I'll no longer be a Capulet.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    0.420878\n",
      "Romeo, come forth; come forth, thou fearful man: Affliction is enamour'd of thy parts, And thou art wedded to calamity.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        0.393959\n",
      "Why, is not this better now than groaning for love? now art thou sociable, now art thou Romeo; now art thou what thou art, by art as well as by nature: for this drivelling love is like a great natural, that runs lolling up and down to hide his bauble in a hole.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          0.389250\n",
      "Nay, an there were two such, we should have none shortly, for one would kill the other. Thou! why, thou wilt quarrel with a man that hath a hair more, or a hair less, in his beard, than thou hast: thou wilt quarrel with a man for cracking nuts, having no other reason but because thou hast hazel eyes: what eye but such an eye would spy out such a quarrel? Thy head is as fun of quarrels as an egg is full of meat, and yet thy head hath been beaten as addle as an egg for quarrelling: thou hast quarrelled with a man for coughing in the street, because he hath wakened thy dog that hath lain asleep in the sun: didst thou not fall out with a tailor for wearing his new doublet before Easter? with another, for tying his new shoes with old riband? and yet thou wilt tutor me from quarrelling!                                                                                                                                                                                                        0.388729\n",
      "I'll give thee armour to keep off that word: Adversity's sweet milk, philosophy, To comfort thee, though thou art banished.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    0.388084\n",
      "How art thou out of breath, when thou hast breath To say to me that thou art out of breath? The excuse that thou dost make in this delay Is longer than the tale thou dost excuse. Is thy news good, or bad? answer to that; Say either, and I'll stay the circumstance: Let me be satisfied, is't good or bad?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                0.386481\n",
      "Talk not to me, for I'll not speak a word: Do as thou wilt, for I have done with thee.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0.380297\n",
      "And stint thou too, I pray thee, nurse, say I.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 0.378455\n",
      "Name: 0, dtype: float64\n",
      "Component 1:\n",
      "Line\n",
      "The ship, sir, the slip; can you not conceive?                                              0.813246\n",
      "Come, sir, your passado.                                                                    0.700177\n",
      "Quarrel sir! no, sir.                                                                       0.690388\n",
      "No, sir, I do not bite my thumb at you, sir, but I bite my thumb, sir.                      0.634224\n",
      "I will be gone, sir, and not trouble you.                                                   0.589495\n",
      "I do bite my thumb, sir.                                                                    0.531522\n",
      "Do you bite your thumb at us, sir?                                                          0.531522\n",
      "Ah sir! ah sir! Well, death's the end of all.                                               0.477886\n",
      "Here, sir, a ring she bid me give you, sir: Hie you, make haste, for it grows very late.    0.472112\n",
      "If you do, sir, I am for you: I serve as good a man as you.                                 0.463713\n",
      "Name: 1, dtype: float64\n",
      "Component 2:\n",
      "Line\n",
      "Ay me!                                                                                               0.918253\n",
      "ay?                                                                                                  0.918253\n",
      "Ay, ay, the cords.                                                                                   0.785669\n",
      "Ay, nurse; what of that? both with an R.                                                             0.783194\n",
      "Ay, ay, a scratch, a scratch; marry, 'tis enough. Where is my page? Go, villain, fetch a surgeon.    0.696835\n",
      "Ay, so I fear; the more is my unrest.                                                                0.676393\n",
      "Ay, by my troth, the case may be amended.                                                            0.631733\n",
      "Ay, mine own fortune in my misery.                                                                   0.619370\n",
      "Ay, if I know the letters and the language.                                                          0.550825\n",
      "Ay, while you live, draw your neck out o' the collar.                                                0.534796\n",
      "Name: 2, dtype: float64\n",
      "Component 3:\n",
      "Line\n",
      "The ship, sir, the slip; can you not conceive?                                                                                                                                                                                                                           0.397316\n",
      "Quarrel sir! no, sir.                                                                                                                                                                                                                                                    0.349724\n",
      "No, sir, I do not bite my thumb at you, sir, but I bite my thumb, sir.                                                                                                                                                                                                   0.347502\n",
      "What wilt thou tell her, nurse? thou dost not mark me.                                                                                                                                                                                                                   0.310116\n",
      "I do bite my thumb, sir.                                                                                                                                                                                                                                                 0.301255\n",
      "Do you bite your thumb at us, sir?                                                                                                                                                                                                                                       0.301255\n",
      "Then say at once what thou dost know in this.                                                                                                                                                                                                                            0.271441\n",
      "To move is to stir; and to be valiant is to stand: therefore, if thou art moved, thou runn'st away.                                                                                                                                                                      0.267235\n",
      "Why, is not this better now than groaning for love? now art thou sociable, now art thou Romeo; now art thou what thou art, by art as well as by nature: for this drivelling love is like a great natural, that runs lolling up and down to hide his bauble in a hole.    0.259971\n",
      "Things for the cook, sir; but I know not what.                                                                                                                                                                                                                           0.257266\n",
      "Name: 3, dtype: float64\n",
      "Component 4:\n",
      "Line\n",
      "Of love?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    0.755136\n",
      "With love's light wings did I o'er-perch these walls; For stony limits cannot hold love out, And what love can do that dares love attempt; Therefore thy kinsmen are no let to me.                                                                                                                                                                                                                                                                                                                                                                                          0.544607\n",
      "I pray thee, chide not; she whom I love now Doth grace for grace and love for love allow; The other did not so.                                                                                                                                                                                                                                                                                                                                                                                                                                                             0.484097\n",
      "That may be must be, love, on Thursday next.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                0.461218\n",
      "If my heart's dear love                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     0.455996\n",
      "Alas, that love, whose view is muffled still, Should, without eyes, see pathways to his will! Where shall we dine? O me! What fray was here? Yet tell me not, for I have heard it all. Here's much to do with hate, but more with love. Why, then, O brawling love! O loving hate! O any thing, of nothing first create! O heavy lightness! serious vanity! Mis-shapen chaos of well-seeming forms! Feather of lead, bright smoke, cold fire, sick health! Still-waking sleep, that is not what it is! This love feel I, that feel no love in this. Dost thou not laugh?    0.431466\n",
      "Farewell! I will omit no opportunity That may convey my greetings, love, to thee.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           0.428557\n",
      "Do not deny to him that you love me.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        0.402151\n",
      "Tell me in sadness, who is that you love.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   0.380084\n",
      "It doth so, holy sir; and there's my master, One that you love.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             0.358412\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#Our SVD data reducer.  We are going to reduce the feature space.\n",
    "svd= TruncatedSVD(400)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)\n",
    "\n",
    "#Looking at what sorts of paragraphs our solution considers similar, for the first five identified topics\n",
    "paras_by_component=pd.DataFrame(X_train_lsa,index=X_train)\n",
    "for i in range(5):\n",
    "    print('Component {}:'.format(i))\n",
    "    print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>Sentence similarity with latent semantic analysis</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:\n",
      "0 Go, be gone. We shall be much unfurnished for this time. What, is my daughter gone to Friar Laurence?\n",
      "1 Give me the letter; I will look on it. Where is the county's page, that raised the watch? Sirrah, what made your master in this place?\n",
      "2 Patience perforce with wilful choler meeting Makes my flesh tremble in their different greeting. I will withdraw: but this intrusion shall Now seeming sweet convert to bitter gall.\n",
      "3 No, 'tis not so deep as a well, nor so wide as a church-door; but 'tis enough,'twill serve: ask for me to-morrow, and you shall find me a grave man. I am peppered, I warrant, for this world. A plague o' both your houses! 'Zounds, a dog, a rat, a mouse, a cat, to scratch a man to death! a braggart, a rogue, a villain, that fights by the book of arithmetic! Why the devil came you between us? I was hurt under your arm.\n",
      "4 'Tis more, 'tis more, his son is elder, sir; His son is thirty.\n",
      "5 I hear some noise. Lady, come from that nest Of death, contagion, and unnatural sleep: A greater power than we can contradict Hath thwarted our intents. Come, come away. Thy husband in thy bosom there lies dead; And Paris too. Come, I'll dispose of thee Among a sisterhood of holy nuns: Stay not to question, for the watch is coming; Come, go, good Juliet, I dare no longer stay.\n",
      "6 Hold; get you gone, be strong and prosperous In this resolve: I'll send a friar with speed To Mantua, with my letters to thy lord.\n",
      "7 O, she doth teach the torches to burn bright! It seems she hangs upon the cheek of night Like a rich jewel in an Ethiope's ear; Beauty too rich for use, for earth too dear! So shows a snowy dove trooping with crows, As yonder lady o'er her fellows shows. The measure done, I'll watch her place of stand, And, touching hers, make blessed my rude hand. Did my heart love till now? forswear it, sight! For I ne'er saw true beauty till this night.\n",
      "8 Ah sir! ah sir! Well, death's the end of all.\n",
      "9 I'll lay fourteen of my teeth, And yet, to my teeth be it spoken, I have but four She is not fourteen. How long is it now To Lammas-tide?\n"
     ]
    }
   ],
   "source": [
    "# Compute document similarity using LSA components\n",
    "similarity = np.asarray(np.asmatrix(X_train_lsa) * np.asmatrix(X_train_lsa).T)\n",
    "#Only taking the first 10 sentences\n",
    "sim_matrix=pd.DataFrame(similarity,index=X_train).iloc[0:10,0:10]\n",
    "#Making a plot\n",
    "ax = sns.heatmap(sim_matrix,yticklabels=range(10))\n",
    "plt.show()\n",
    "\n",
    "#Generating a key for the plot.\n",
    "print('Key:')\n",
    "for i in range(10):\n",
    "    print(i,sim_matrix.index[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Assess your models using cross-validation and determine whether one model performed better.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training</th>\n",
       "      <th>testing</th>\n",
       "      <th>cross_val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.988072</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.16 (+/- 0.13)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>0.946322</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.27 (+/- 0.04)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradient boosting</th>\n",
       "      <td>0.968191</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.22 (+/- 0.03)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     training   testing    cross_val_acc\n",
       "random forest        0.988072  0.160714  0.16 (+/- 0.13)\n",
       "logistic regression  0.946322  0.238095  0.27 (+/- 0.04)\n",
       "gradient boosting    0.968191  0.229167  0.22 (+/- 0.03)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = ['random forest', 'logistic regression', 'gradient boosting']\n",
    "\n",
    "models = pd.DataFrame(index=order)\n",
    "\n",
    "models['training'] = [0.9880715705765407, 0.9463220675944334, 0.9681908548707754]\n",
    "models['testing'] = [0.16071428571428573,0.23809523809523808, 0.22916666666666666]\n",
    "models['cross_val_acc'] = ['0.16 (+/- 0.13)','0.27 (+/- 0.04)','0.23 (+/- 0.03)']\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like logistic regression scored better in testing and the cross validation, though gradient boosting and random forest were both better then it on the training set - which sounds a lot like overfitting. Therefore the model that performed the best on the BOW features was the **logistic regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Pick one of the models and try to increase accuracy by at least 5 percentage points.\n",
    "\n",
    "Let's try to improve the logistic regression model with the BOW features, since that one performed the best. First, let's take another look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>Scene</th>\n",
       "      <th>Scene_Name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Line</th>\n",
       "      <th>parsed</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>be</th>\n",
       "      <th>and</th>\n",
       "      <th>the</th>\n",
       "      <th>...</th>\n",
       "      <th>intercession</th>\n",
       "      <th>stead</th>\n",
       "      <th>plain</th>\n",
       "      <th>homely</th>\n",
       "      <th>plainly</th>\n",
       "      <th>woo'd</th>\n",
       "      <th>forsake</th>\n",
       "      <th>maria</th>\n",
       "      <th>brine</th>\n",
       "      <th>Speaker_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>Gregory, o' my word, we'll not carry coals.</td>\n",
       "      <td>(Gregory, ,, o, ', my, word, ,, we, 'll, not, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>No, for then we should be colliers.</td>\n",
       "      <td>(No, ,, for, then, we, should, be, colliers, .)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I mean, an we be in choler, we'll draw.</td>\n",
       "      <td>(I, mean, ,, an, we, be, in, choler, ,, we, 'l...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>Ay, while you live, draw your neck out o' the ...</td>\n",
       "      <td>(Ay, ,, while, you, live, ,, draw, your, neck,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I strike quickly, being moved.</td>\n",
       "      <td>(I, strike, quickly, ,, being, moved, .)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2007 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Act    Scene                 Scene_Name  Speaker  \\\n",
       "0  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "1  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "2  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "3  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "4  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "\n",
       "                                                Line  \\\n",
       "0        Gregory, o' my word, we'll not carry coals.   \n",
       "1                No, for then we should be colliers.   \n",
       "2            I mean, an we be in choler, we'll draw.   \n",
       "3  Ay, while you live, draw your neck out o' the ...   \n",
       "4                     I strike quickly, being moved.   \n",
       "\n",
       "                                              parsed  -PRON-  be  and  the  \\\n",
       "0  (Gregory, ,, o, ', my, word, ,, we, 'll, not, ...       2   0    0    0   \n",
       "1    (No, ,, for, then, we, should, be, colliers, .)       1   1    0    0   \n",
       "2  (I, mean, ,, an, we, be, in, choler, ,, we, 'l...       3   1    0    0   \n",
       "3  (Ay, ,, while, you, live, ,, draw, your, neck,...       2   0    0    1   \n",
       "4           (I, strike, quickly, ,, being, moved, .)       1   1    0    0   \n",
       "\n",
       "        ...        intercession  stead  plain  homely  plainly  woo'd  \\\n",
       "0       ...                   0      0      0       0        0      0   \n",
       "1       ...                   0      0      0       0        0      0   \n",
       "2       ...                   0      0      0       0        0      0   \n",
       "3       ...                   0      0      0       0        0      0   \n",
       "4       ...                   0      0      0       0        0      0   \n",
       "\n",
       "   forsake  maria  brine  Speaker_counts  \n",
       "0        0      0      0              20  \n",
       "1        0      0      0              15  \n",
       "2        0      0      0              20  \n",
       "3        0      0      0              15  \n",
       "4        0      0      0              20  \n",
       "\n",
       "[5 rows x 2007 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plus_bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <em>feature engineering</em>\n",
    "\n",
    "For features, we'll use Act and Scene. I'll add some more features too - first, word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plus_bow['word_count'] = len(df['parsed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also add a count of the unique parts of speech in each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_pos(Series):\n",
    "    \n",
    "    allpos = [token.pos_ for token in Series]\n",
    "        \n",
    "    return (len(set(allpos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plus_bow['unique_pos'] = df_plus_bow['parsed'].apply(unique_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and use word vectors on the sentence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30085 29678\n"
     ]
    }
   ],
   "source": [
    "# First I'm double checking that all of the words in the doc have vectors already.\n",
    "\n",
    "count = 0\n",
    "for token in complete_doc:\n",
    "    if token.has_vector:\n",
    "        count+=1\n",
    "    \n",
    "print(len(complete_doc), count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "# couldnt search complete_doc so rejoined the lines to search through w/ regular expression\n",
    "okay_again = ' '.join(all_the_lines)\n",
    "\n",
    "\n",
    "def get_vector(value):\n",
    "    \n",
    "    # get the location of the sentence in the nlp loaded text\n",
    "\n",
    "    target = re.compile(value)\n",
    "    \n",
    "    # find the target in complete_doc and return it as an itme\n",
    "    found = target.search(okay_again)\n",
    "    \n",
    "    if found != None:\n",
    "    \n",
    "        # beginning and end\n",
    "        start = found.start()\n",
    "        end = found.end()\n",
    "    \n",
    "        span = complete_doc[start:end]\n",
    "        \n",
    "        if span.has_vector:\n",
    "            return span.vector_norm\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df_plus_bow['vector'] = df_plus_bow['Line'].apply(get_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>Scene</th>\n",
       "      <th>Scene_Name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Line</th>\n",
       "      <th>parsed</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>be</th>\n",
       "      <th>and</th>\n",
       "      <th>the</th>\n",
       "      <th>...</th>\n",
       "      <th>homely</th>\n",
       "      <th>plainly</th>\n",
       "      <th>woo'd</th>\n",
       "      <th>forsake</th>\n",
       "      <th>maria</th>\n",
       "      <th>brine</th>\n",
       "      <th>Speaker_counts</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_pos</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>Gregory, o' my word, we'll not carry coals.</td>\n",
       "      <td>(Gregory, ,, o, ', my, word, ,, we, 'll, not, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>839</td>\n",
       "      <td>8</td>\n",
       "      <td>3.022147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>No, for then we should be colliers.</td>\n",
       "      <td>(No, ,, for, then, we, should, be, colliers, .)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>839</td>\n",
       "      <td>7</td>\n",
       "      <td>3.289926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I mean, an we be in choler, we'll draw.</td>\n",
       "      <td>(I, mean, ,, an, we, be, in, choler, ,, we, 'l...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>839</td>\n",
       "      <td>6</td>\n",
       "      <td>3.212513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>Ay, while you live, draw your neck out o' the ...</td>\n",
       "      <td>(Ay, ,, while, you, live, ,, draw, your, neck,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>839</td>\n",
       "      <td>9</td>\n",
       "      <td>3.014298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I strike quickly, being moved.</td>\n",
       "      <td>(I, strike, quickly, ,, being, moved, .)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>839</td>\n",
       "      <td>4</td>\n",
       "      <td>3.084016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2010 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Act    Scene                 Scene_Name  Speaker  \\\n",
       "0  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "1  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "2  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "3  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "4  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "\n",
       "                                                Line  \\\n",
       "0        Gregory, o' my word, we'll not carry coals.   \n",
       "1                No, for then we should be colliers.   \n",
       "2            I mean, an we be in choler, we'll draw.   \n",
       "3  Ay, while you live, draw your neck out o' the ...   \n",
       "4                     I strike quickly, being moved.   \n",
       "\n",
       "                                              parsed  -PRON-  be  and  the  \\\n",
       "0  (Gregory, ,, o, ', my, word, ,, we, 'll, not, ...       2   0    0    0   \n",
       "1    (No, ,, for, then, we, should, be, colliers, .)       1   1    0    0   \n",
       "2  (I, mean, ,, an, we, be, in, choler, ,, we, 'l...       3   1    0    0   \n",
       "3  (Ay, ,, while, you, live, ,, draw, your, neck,...       2   0    0    1   \n",
       "4           (I, strike, quickly, ,, being, moved, .)       1   1    0    0   \n",
       "\n",
       "     ...     homely  plainly  woo'd  forsake  maria  brine  Speaker_counts  \\\n",
       "0    ...          0        0      0        0      0      0              20   \n",
       "1    ...          0        0      0        0      0      0              15   \n",
       "2    ...          0        0      0        0      0      0              20   \n",
       "3    ...          0        0      0        0      0      0              15   \n",
       "4    ...          0        0      0        0      0      0              20   \n",
       "\n",
       "   word_count  unique_pos    vector  \n",
       "0         839           8  3.022147  \n",
       "1         839           7  3.289926  \n",
       "2         839           6  3.212513  \n",
       "3         839           9  3.014298  \n",
       "4         839           4  3.084016  \n",
       "\n",
       "[5 rows x 2010 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plus_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert act and scene to numbers\n",
    "\n",
    "def get_numeric(name):\n",
    "    \n",
    "    roman = {'IV' : 4, 'V': 5, 'VI' : 6, 'VII' : 7}\n",
    "    \n",
    "    pieces = name.split()\n",
    "    if 'V' not in pieces[1]:\n",
    "        return len(pieces[1])\n",
    "    else:\n",
    "        return roman[pieces[1]]\n",
    "\n",
    "df['Act_num'] = df['Act'].apply(get_numeric)\n",
    "df['Scene_num'] = df['Scene'].apply(get_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <em>fitting the logistic model</em>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. getting the testing and training samples\n",
    "\n",
    "Y_new_f = df_plus_bow_max['Speaker']\n",
    "X_new_f = df_plus_bow_max.drop(['Act','Scene', 'Scene_Name', 'Speaker', 'Line', 'parsed'], 1)\n",
    "\n",
    "X_train_new_f, X_test_new_f, y_train_new_f, y_test_new_f = train_test_split(X_new_f, \n",
    "                                                    Y_new_f,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(469, 2001) (469,)\n",
      "Training set score: 0.9744136460554371\n",
      "\n",
      "Test set score: 0.4249201277955272\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_new_f, y_train_new_f)\n",
    "print(X_train_new_f.shape, y_train_new_f.shape)\n",
    "print('Training set score:', lr.score(X_train_new_f, y_train_new_f))\n",
    "print('\\nTest set score:', lr.score(X_test_new_f, y_test_new_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_lr2 = cross_val_score(lr, X_train_new_f, y_train_new_f, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (validate_lr2.mean(), validate_lr2.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
