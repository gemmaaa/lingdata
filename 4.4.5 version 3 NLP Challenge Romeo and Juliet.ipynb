{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4.5 NLP Challenge using Romeo and Juliet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import shakespeare, stopwords #,  qc\n",
    "\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 . Data processing, cleaning, language parsing\n",
    "\n",
    "First, taking a look at documents in shakespeare, and picking one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a_and_c.xml', 'dream.xml', 'hamlet.xml', 'j_caesar.xml', 'macbeth.xml', 'merchant.xml', 'othello.xml', 'r_and_j.xml']\n"
     ]
    }
   ],
   "source": [
    "print(shakespeare.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\"?>\r\n",
      "<?xml-stylesheet type=\"text/css\" href=\"shakes.css\"?>\r\n",
      "<!-- <!DOCTYPE PLAY SYSTEM \"play.dtd\"> -->\r\n",
      "\r\n",
      "<PLAY>\r\n",
      "<TITLE>The Tragedy \n"
     ]
    }
   ],
   "source": [
    "rj = shakespeare.raw('r_and_j.xml')\n",
    "print(rj[:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally I didn't know aout XML Element tree so I tried using a lot of regular expressions - a useful explanation of the specific regular expression used is [here](https://stackoverflow.com/questions/8784396/delete-the-words-between-two-delimiters-in-python) (for future reference).\n",
    "\n",
    "However, then I found out about ElementTree, and learned a tiny bit about parsing with it. Here are some tutorials that I am still looking at: [this one from effbott](http://effbot.org/zone/element.htm), and [the python docs](https://docs.python.org/3.5/library/xml.etree.elementtree.html), [datacamp](https://www.datacamp.com/community/tutorials/python-xml-elementtree), [nltk](https://www.nltk.org/book/ch11.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse('/Users/gemma/nltk_data/corpora/shakespeare/r_and_j.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the categories of elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACT',\n",
       " 'FM',\n",
       " 'GRPDESCR',\n",
       " 'LINE',\n",
       " 'P',\n",
       " 'PERSONA',\n",
       " 'PERSONAE',\n",
       " 'PGROUP',\n",
       " 'PLAY',\n",
       " 'PLAYSUBT',\n",
       " 'PROLOGUE',\n",
       " 'SCENE',\n",
       " 'SCNDESCR',\n",
       " 'SPEAKER',\n",
       " 'SPEECH',\n",
       " 'STAGEDIR',\n",
       " 'TITLE'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([elem.tag for elem in root.iter()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaining an understanding of the structure of the document / tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parent_map = dict((c, p) for p in tree.getiterator() for c in p)\n",
    "\n",
    "#for key in parent_map:\n",
    "#    if key.text:\n",
    "#        print(\"key tag:  \", key.tag, \" key text: \", key.text, \" parent tag: \", parent_map[key].tag, \" parent text: \", \n",
    "#             parent_map[key].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will extract the elements of interest and put them in a dataframe.\n",
    "\n",
    "At the same time, I'll clean up the lines using the below function, as we go, for the sake of efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACT I\n",
      "SCENE I.  Verona. A public place.\n",
      "SCENE II.  A street.\n",
      "SCENE III.  A room in Capulet's house.\n",
      "SCENE IV.  A street.\n",
      "SCENE V.  A hall in Capulet's house.\n",
      "ACT II\n",
      "SCENE I.  A lane by the wall of Capulet's orchard.\n",
      "SCENE II.  Capulet's orchard.\n",
      "SCENE III.  Friar Laurence's cell.\n",
      "SCENE IV.  A street.\n",
      "SCENE V.  Capulet's orchard.\n",
      "SCENE VI.  Friar Laurence's cell.\n",
      "ACT III\n",
      "SCENE I.  A public place.\n",
      "SCENE II.  Capulet's orchard.\n",
      "SCENE III.  Friar Laurence's cell.\n",
      "SCENE IV.  A room in Capulet's house.\n",
      "SCENE V.  Capulet's orchard.\n",
      "ACT IV\n",
      "SCENE I.  Friar Laurence's cell.\n",
      "SCENE II.  Hall in Capulet's house.\n",
      "SCENE III.  Juliet's chamber.\n",
      "SCENE IV.  Hall in Capulet's house.\n",
      "SCENE V.  Juliet's chamber.\n",
      "ACT V\n",
      "SCENE I.  Mantua. A street.\n",
      "SCENE II.  Friar Laurence's cell.\n",
      "SCENE III.  A churchyard; in it a tomb belonging to the Capulets.\n"
     ]
    }
   ],
   "source": [
    "# trying to get all of the speakers and their lines in an array\n",
    "\n",
    "rows = {}\n",
    "\n",
    "l = 0 \n",
    "\n",
    "for i, act in enumerate(root.findall('ACT')):\n",
    "    for s, act_t in enumerate(act.findall('TITLE')):\n",
    "        print(act_t.text)\n",
    "    for j, scene in enumerate(act.findall('SCENE')):\n",
    "        for q, scene_t in enumerate(scene.findall('TITLE')):\n",
    "            print(scene_t.text)\n",
    "            only_number = scene_t.text.split('.',1)\n",
    "        for k, speech in enumerate(scene.findall('SPEECH')):\n",
    "            for i, speaker in enumerate(speech.findall('SPEAKER')):\n",
    "                \n",
    "                # there is an instance of LADY  CAPULET which shouldbe LADY CAPULET\n",
    "                if speaker.text == 'LADY  CAPULET':\n",
    "                    speaker.text = speaker.text.replace('LADY  CAPULET', 'LADY CAPULET')\n",
    "                \n",
    "                all_lines = []\n",
    "                for line in speech.findall('LINE'):\n",
    "                    if line.text:\n",
    "                        line.text = text_cleaner(line.text)\n",
    "                        all_lines.append(line.text)\n",
    "                \n",
    "                rows[l] = ([act_t.text, only_number[0], only_number[1], speaker.text, ' '.join(all_lines)])\n",
    "                l+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>Scene</th>\n",
       "      <th>Scene_Name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>Gregory, o' my word, we'll not carry coals.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>No, for then we should be colliers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I mean, an we be in choler, we'll draw.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>Ay, while you live, draw your neck out o' the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I strike quickly, being moved.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Act    Scene                 Scene_Name  Speaker  \\\n",
       "0  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "1  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "2  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "3  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "4  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "\n",
       "                                                Line  \n",
       "0        Gregory, o' my word, we'll not carry coals.  \n",
       "1                No, for then we should be colliers.  \n",
       "2            I mean, an we be in choler, we'll draw.  \n",
       "3  Ay, while you live, draw your neck out o' the ...  \n",
       "4                     I strike quickly, being moved.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(data=rows, orient='index', columns=['Act', 'Scene', 'Scene_Name','Speaker', 'Line'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's parse the lines in a new column with spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      ",\n",
      "for\n",
      "then\n",
      "-PRON-\n",
      "should\n",
      "be\n",
      "collier\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# first let me make sure this will work\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "testing = nlp(df.loc[1, 'Line'])\n",
    "\n",
    "for token in testing:\n",
    "    print(token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it worked! let's apply it to the whole dataframe of lines\n",
    "\n",
    "df['parsed'] = df['Line'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>Scene</th>\n",
       "      <th>Scene_Name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Line</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>Gregory, o' my word, we'll not carry coals.</td>\n",
       "      <td>(Gregory, ,, o, ', my, word, ,, we, 'll, not, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>No, for then we should be colliers.</td>\n",
       "      <td>(No, ,, for, then, we, should, be, colliers, .)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I mean, an we be in choler, we'll draw.</td>\n",
       "      <td>(I, mean, ,, an, we, be, in, choler, ,, we, 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>Ay, while you live, draw your neck out o' the ...</td>\n",
       "      <td>(Ay, ,, while, you, live, ,, draw, your, neck,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I strike quickly, being moved.</td>\n",
       "      <td>(I, strike, quickly, ,, being, moved, .)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Act    Scene                 Scene_Name  Speaker  \\\n",
       "0  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "1  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "2  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "3  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "4  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "\n",
       "                                                Line  \\\n",
       "0        Gregory, o' my word, we'll not carry coals.   \n",
       "1                No, for then we should be colliers.   \n",
       "2            I mean, an we be in choler, we'll draw.   \n",
       "3  Ay, while you live, draw your neck out o' the ...   \n",
       "4                     I strike quickly, being moved.   \n",
       "\n",
       "                                              parsed  \n",
       "0  (Gregory, ,, o, ', my, word, ,, we, 'll, not, ...  \n",
       "1    (No, ,, for, then, we, should, be, colliers, .)  \n",
       "2  (I, mean, ,, an, we, be, in, choler, ,, we, 'l...  \n",
       "3  (Ay, ,, while, you, live, ,, draw, your, neck,...  \n",
       "4           (I, strike, quickly, ,, being, moved, .)  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>Scene</th>\n",
       "      <th>Scene_Name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Line</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Act, Scene, Scene_Name, Speaker, Line, parsed]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double checking that LADY  CAPULET was replaced w correctly spaced name\n",
    "df[df['Speaker'] == 'LADY  CAPULET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating features using two different NLP methods, BOW and tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. BOW**\n",
    "\n",
    "In order to get a list of the common words from the text, first I'm going to put all the lines together into one text (one string) and then run spaCy on the resulting text. This is a little redundant since I already ran spaCy on each individual line, but it is the best way I could think of to keep the lines organized by speaker in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_lines = []\n",
    "\n",
    "# just look at \"LINE\"s in the tree\n",
    "for line in root.iter('LINE'):\n",
    "    # make sure it's a string (ignore the \"None\" entries)\n",
    "    if isinstance(line.text, str):\n",
    "        all_the_lines.append(line.text)\n",
    "    \n",
    "complete_doc = nlp((' '.join(all_the_lines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30085"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many unique words are in the doc?\n",
    "all_word = [token for token in complete_doc]\n",
    "\n",
    "len(set(all_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I'll use the bag of words function to get the most common words across all of the lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = bag_of_words(complete_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the common words as word counts in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_features(original_df, common_words):\n",
    "    \n",
    "    # copy the dataframe so your bow features will be in a new one and wont affect the original data\n",
    "    df = original_df.copy(deep=True)\n",
    "    \n",
    "    # Add the words to the dataframe and set all counts to 0\n",
    "    for word in common_words:\n",
    "        df[word] = 0\n",
    "        \n",
    "    # Process each row, counting the occurrence of words in each parsed sentence.\n",
    "    for i, sentence in enumerate(df['parsed']):\n",
    "        \n",
    "        # I already converted the sentence to lemmas, and filtered out punctuation and stop words.\n",
    "        # Now I'm just going to get a list of the words in each line that are in the common words list.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if token.lemma_ in common_words\n",
    "                ]\n",
    "        \n",
    "        # Populate the row with word counts\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n"
     ]
    }
   ],
   "source": [
    "df_plus_bow = bow_features(df,common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's also convert act and scene to numbers\n",
    "\n",
    "def get_numeric(name):\n",
    "    \n",
    "    roman = {'IV' : 4, 'V': 5, 'VI' : 6, 'VII' : 7}\n",
    "    \n",
    "    pieces = name.split()\n",
    "    if 'V' not in pieces[1]:\n",
    "        return len(pieces[1])\n",
    "    else:\n",
    "        return roman[pieces[1]]\n",
    "\n",
    "df_plus_bow['Act_num'] = df_plus_bow['Act'].apply(get_numeric)\n",
    "df_plus_bow['Scene_num'] = df_plus_bow['Scene'].apply(get_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>Scene</th>\n",
       "      <th>Scene_Name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Line</th>\n",
       "      <th>parsed</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>be</th>\n",
       "      <th>and</th>\n",
       "      <th>the</th>\n",
       "      <th>...</th>\n",
       "      <th>quench</th>\n",
       "      <th>issue</th>\n",
       "      <th>throw</th>\n",
       "      <th>sentence</th>\n",
       "      <th>citizen</th>\n",
       "      <th>canker'd</th>\n",
       "      <th>disturb</th>\n",
       "      <th>forfeit</th>\n",
       "      <th>Act_num</th>\n",
       "      <th>Scene_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>Gregory, o' my word, we'll not carry coals.</td>\n",
       "      <td>(Gregory, ,, o, ', my, word, ,, we, 'll, not, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>No, for then we should be colliers.</td>\n",
       "      <td>(No, ,, for, then, we, should, be, colliers, .)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I mean, an we be in choler, we'll draw.</td>\n",
       "      <td>(I, mean, ,, an, we, be, in, choler, ,, we, 'l...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>Ay, while you live, draw your neck out o' the ...</td>\n",
       "      <td>(Ay, ,, while, you, live, ,, draw, your, neck,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I strike quickly, being moved.</td>\n",
       "      <td>(I, strike, quickly, ,, being, moved, .)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1008 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Act    Scene                 Scene_Name  Speaker  \\\n",
       "0  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "1  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "2  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "3  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "4  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "\n",
       "                                                Line  \\\n",
       "0        Gregory, o' my word, we'll not carry coals.   \n",
       "1                No, for then we should be colliers.   \n",
       "2            I mean, an we be in choler, we'll draw.   \n",
       "3  Ay, while you live, draw your neck out o' the ...   \n",
       "4                     I strike quickly, being moved.   \n",
       "\n",
       "                                              parsed  -PRON-  be  and  the  \\\n",
       "0  (Gregory, ,, o, ', my, word, ,, we, 'll, not, ...       2   0    0    0   \n",
       "1    (No, ,, for, then, we, should, be, colliers, .)       1   1    0    0   \n",
       "2  (I, mean, ,, an, we, be, in, choler, ,, we, 'l...       3   1    0    0   \n",
       "3  (Ay, ,, while, you, live, ,, draw, your, neck,...       2   0    0    1   \n",
       "4           (I, strike, quickly, ,, being, moved, .)       1   1    0    0   \n",
       "\n",
       "     ...      quench  issue  throw  sentence  citizen  canker'd  disturb  \\\n",
       "0    ...           0      0      0         0        0         0        0   \n",
       "1    ...           0      0      0         0        0         0        0   \n",
       "2    ...           0      0      0         0        0         0        0   \n",
       "3    ...           0      0      0         0        0         0        0   \n",
       "4    ...           0      0      0         0        0         0        0   \n",
       "\n",
       "   forfeit  Act_num  Scene_num  \n",
       "0        0        1          1  \n",
       "1        0        1          1  \n",
       "2        0        1          1  \n",
       "3        0        1          1  \n",
       "4        0        1          1  \n",
       "\n",
       "[5 rows x 1008 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plus_bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the bow features in a model soon, but first I'll create the features using df-idf.\n",
    "\n",
    "**b. df-idf**\n",
    "\n",
    "Let's take a look at the dataframe again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>Scene</th>\n",
       "      <th>Scene_Name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Line</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>Gregory, o' my word, we'll not carry coals.</td>\n",
       "      <td>(Gregory, ,, o, ', my, word, ,, we, 'll, not, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>No, for then we should be colliers.</td>\n",
       "      <td>(No, ,, for, then, we, should, be, colliers, .)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I mean, an we be in choler, we'll draw.</td>\n",
       "      <td>(I, mean, ,, an, we, be, in, choler, ,, we, 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>Ay, while you live, draw your neck out o' the ...</td>\n",
       "      <td>(Ay, ,, while, you, live, ,, draw, your, neck,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I strike quickly, being moved.</td>\n",
       "      <td>(I, strike, quickly, ,, being, moved, .)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Act    Scene                 Scene_Name  Speaker  \\\n",
       "0  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "1  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "2  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "3  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "4  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "\n",
       "                                                Line  \\\n",
       "0        Gregory, o' my word, we'll not carry coals.   \n",
       "1                No, for then we should be colliers.   \n",
       "2            I mean, an we be in choler, we'll draw.   \n",
       "3  Ay, while you live, draw your neck out o' the ...   \n",
       "4                     I strike quickly, being moved.   \n",
       "\n",
       "                                              parsed  \n",
       "0  (Gregory, ,, o, ', my, word, ,, we, 'll, not, ...  \n",
       "1    (No, ,, for, then, we, should, be, colliers, .)  \n",
       "2  (I, mean, ,, an, we, be, in, choler, ,, we, 'l...  \n",
       "3  (Ay, ,, while, you, live, ,, draw, your, neck,...  \n",
       "4           (I, strike, quickly, ,, being, moved, .)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks ready to run the model, so let's go to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Supervised learning models\n",
    "\n",
    "Using the different sets of features from above. First let's use bow with random forest and see if we can predict the speaker.\n",
    "\n",
    "a. **BOW** \n",
    "\n",
    "<em>i. with Random Forest</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save values to make a table\n",
    "training_all = []\n",
    "testing_all = []\n",
    "cross_val_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9900596421471173\n",
      "\n",
      "Test set score: 0.25297619047619047\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = df_plus_bow['Speaker']\n",
    "X = df_plus_bow.drop(['Act','Scene', 'Scene_Name','Speaker', 'Line', 'parsed'], 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "training_all.append(rfc.score(X_train, y_train))\n",
    "testing_all.append(rfc.score(X_test, y_test))\n",
    "\n",
    "print('Training set score:', training_all[-1])\n",
    "print('\\nTest set score:', testing_all[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "validate = cross_val_score(rfc, X_test, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The warning shows a problem with the number of members in each class, meaning in this case the number of lines for some of the speakers. Let's see if we can drop speakers with less than a certain threshold of lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the counts of each speaker and add it as a column\n",
    "df_plus_bow['Speaker_counts'] = df_plus_bow.groupby('Speaker')['Line'].transform('count')\n",
    "\n",
    "# drop lines whose speakers have less than 10 lines from the rows\n",
    "df_plus_bow_max = df_plus_bow.drop(df_plus_bow[df_plus_bow.Speaker_counts < 10].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Speaker\n",
       "ROMEO             163\n",
       "JULIET            118\n",
       "Nurse              89\n",
       "BENVOLIO           64\n",
       "MERCUTIO           62\n",
       "FRIAR LAURENCE     55\n",
       "CAPULET            50\n",
       "LADY CAPULET       45\n",
       "PARIS              23\n",
       "SAMPSON            20\n",
       "TYBALT             17\n",
       "PRINCE             16\n",
       "GREGORY            15\n",
       "PETER              13\n",
       "BALTHASAR          12\n",
       "Servant            10\n",
       "MONTAGUE           10\n",
       "Name: Speaker_counts, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check it worked \n",
    "df_plus_bow_max.groupby('Speaker')['Speaker_counts'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9893390191897654\n",
      "\n",
      "Test set score: 0.4984025559105431\n"
     ]
    }
   ],
   "source": [
    "# re run rfc\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y_max = df_plus_bow_max['Speaker']\n",
    "X_max = df_plus_bow_max.drop(['Act','Scene', 'Scene_Name','Speaker', \n",
    "                              'Line', 'parsed'], 1)\n",
    "\n",
    "X_train_max, X_test_max, y_train_max, y_test_max = train_test_split(X_max, \n",
    "                                                    Y_max,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train_max, y_train_max)\n",
    "\n",
    "training_all[0] = rfc.score(X_train_max, y_train_max)\n",
    "testing_all[0] = rfc.score(X_test_max, y_test_max)\n",
    "\n",
    "print('Training set score:', training_all[0])\n",
    "print('\\nTest set score:', testing_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate = cross_val_score(rfc, X_train_max, y_train_max, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3592233  0.44791667 0.40425532 0.44318182 0.61363636]\n",
      "0.4536426937209317 +/- 0.1722656697320356\n"
     ]
    }
   ],
   "source": [
    "print(validate)\n",
    "print(np.mean(validate), '+/-', np.std(validate)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45 (+/- 0.17)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (validate.mean(), validate.std() * 2))\n",
    "\n",
    "cross_val_all.append(\"%0.2f (+/- %0.2f)\" % (validate.mean(), validate.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>ii. with Logistic Regression</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(469, 1003) (469,)\n",
      "Training set score: 0.9744136460554371\n",
      "\n",
      "Test set score: 0.46645367412140576\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train_max, y_train_max)\n",
    "print(X_train_max.shape, y_train_max.shape)\n",
    "\n",
    "training_all.append(lr.score(X_train_max, y_train_max))\n",
    "testing_all.append(lr.score(X_test_max, y_test_max))\n",
    "    \n",
    "print('Training set score:', training_all[-1])\n",
    "print('\\nTest set score:', testing_all[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_lr = cross_val_score(lr, X_train_max, y_train_max, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.51 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (validate_lr.mean(), validate_lr.std() * 2))\n",
    "\n",
    "cross_val_all.append(\"%0.2f (+/- %0.2f)\" % (validate_lr.mean(), validate_lr.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>iii. with Gradient Boosting</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.0\n",
      "\n",
      "Test set score: 1.0\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train_max, y_train_max)\n",
    "\n",
    "training_all.append(clf.score(X_train_max, y_train_max))\n",
    "testing_all.append(clf.score(X_test_max, y_test_max))\n",
    "\n",
    "print('Training set score:', training_all[-1])\n",
    "print('\\nTest set score:', testing_all[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_gb = cross_val_score(clf,X_train_max,y_train_max,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (validate_gb.mean(), validate_gb.std() * 2))\n",
    "\n",
    "cross_val_all.append(\"%0.2f (+/- %0.2f)\" % (validate_gb.mean(), validate_gb.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. tf-idf**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll run the tf-idf vectorizer to get the vectors for each line. Normally this is on a paragraph basis but since this is a play lines should be a good substitute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_test = train_test_split(df['Line'], test_size=0.4, random_state=0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.75, # drop words that occur in more than 75 percent of the paragraphs\n",
    "                             min_df=3, # only use words that appear at least 3 times\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case \n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "#Applying the vectorizer\n",
    "lines_tfidf=vectorizer.fit_transform(df['Line'])\n",
    "print(\"Number of features: %d\" % lines_tfidf.get_shape()[1])\n",
    "\n",
    "# inititally tried model with parameters: max_df 0.75, min_df 10, # of features was 187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: Gregory, o' my word, we'll not carry coals.\n",
      "Tf_idf vector: {'laurence': 0.41324507177540226, 'friar': 0.336058721652412, 'gone': 0.6486787186462298, 'daughter': 0.3673003861933039, 'time': 0.31424202170388116, 'shall': 0.2486993050410113}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#splitting into training and test sets\n",
    "X_train_tfidf, X_test_tfidf= train_test_split(lines_tfidf, test_size=0.4, random_state=0)\n",
    "\n",
    "#Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "\n",
    "#number of paragraphs\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "#A list of dictionaries, one per paragraph\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n",
    "#List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "#for each paragraph, lists the feature words and their tf-idf scores\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
    "\n",
    "#Keep in mind that the log base 2 of 1 is 0, so a tf-idf score of 0 indicates that the word was\n",
    "# present once in that sentence.\n",
    "print('Original sentence:', X_train[0])\n",
    "print('Tf_idf vector:', tfidf_bypara[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>Dimension reduction</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 98.96642355305403\n",
      "Component 0:\n",
      "Line\n",
      "Thou know'st the mask of night is on my face, Else would a maiden blush bepaint my cheek For that which thou hast heard me speak to-night Fain would I dwell on form, fain, fain deny What I have spoke: but farewell compliment! Dost thou love me? I know thou wilt say 'Ay,' And I will take thy word: yet if thou swear'st, Thou mayst prove false; at lovers' perjuries Then say, Jove laughs. O gentle Romeo, If thou dost love, pronounce it faithfully: Or if thou think'st I am too quickly won, I'll frown and be perverse an say thee nay, So thou wilt woo; but else, not for the world. In truth, fair Montague, I am too fond, And therefore thou mayst think my 'havior light: But trust me, gentleman, I'll prove more true Than those that have more cunning to be strange. I should have been more strange, I must confess, But that thou overheard'st, ere I was ware, My true love's passion: therefore pardon me, And not impute this yielding to light love, Which the dark night hath so discovered.    0.521966\n",
      "Thou canst not speak of that thou dost not feel: Wert thou as young as I, Juliet thy love, An hour but married, Tybalt murdered, Doting like me and like me banished, Then mightst thou speak, then mightst thou tear thy hair, And fall upon the ground, as I do now, Taking the measure of an unmade grave.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  0.429345\n",
      "O Romeo, Romeo! wherefore art thou Romeo? Deny thy father and refuse thy name; Or, if thou wilt not, be but sworn my love, And I'll no longer be a Capulet.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    0.420945\n",
      "Name: 0, dtype: float64\n",
      "Component 1:\n",
      "Line\n",
      "The ship, sir, the slip; can you not conceive?    0.813242\n",
      "Come, sir, your passado.                          0.700298\n",
      "Quarrel sir! no, sir.                             0.690153\n",
      "Name: 1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#Our SVD data reducer.  We are going to reduce the feature space.\n",
    "svd= TruncatedSVD(400)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)\n",
    "\n",
    "#Looking at what sorts of paragraphs our solution considers similar, for the first five identified topics\n",
    "paras_by_component=pd.DataFrame(X_train_lsa,index=X_train)\n",
    "for i in range(2):\n",
    "    print('Component {}:'.format(i))\n",
    "    print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>Sentence similarity with latent semantic analysis</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:\n",
      "0 Go, be gone. We shall be much unfurnished for this time. What, is my daughter gone to Friar Laurence?\n",
      "1 Give me the letter; I will look on it. Where is the county's page, that raised the watch? Sirrah, what made your master in this place?\n",
      "2 Patience perforce with wilful choler meeting Makes my flesh tremble in their different greeting. I will withdraw: but this intrusion shall Now seeming sweet convert to bitter gall.\n",
      "3 No, 'tis not so deep as a well, nor so wide as a church-door; but 'tis enough,'twill serve: ask for me to-morrow, and you shall find me a grave man. I am peppered, I warrant, for this world. A plague o' both your houses! 'Zounds, a dog, a rat, a mouse, a cat, to scratch a man to death! a braggart, a rogue, a villain, that fights by the book of arithmetic! Why the devil came you between us? I was hurt under your arm.\n",
      "4 'Tis more, 'tis more, his son is elder, sir; His son is thirty.\n",
      "5 I hear some noise. Lady, come from that nest Of death, contagion, and unnatural sleep: A greater power than we can contradict Hath thwarted our intents. Come, come away. Thy husband in thy bosom there lies dead; And Paris too. Come, I'll dispose of thee Among a sisterhood of holy nuns: Stay not to question, for the watch is coming; Come, go, good Juliet, I dare no longer stay.\n",
      "6 Hold; get you gone, be strong and prosperous In this resolve: I'll send a friar with speed To Mantua, with my letters to thy lord.\n",
      "7 O, she doth teach the torches to burn bright! It seems she hangs upon the cheek of night Like a rich jewel in an Ethiope's ear; Beauty too rich for use, for earth too dear! So shows a snowy dove trooping with crows, As yonder lady o'er her fellows shows. The measure done, I'll watch her place of stand, And, touching hers, make blessed my rude hand. Did my heart love till now? forswear it, sight! For I ne'er saw true beauty till this night.\n",
      "8 Ah sir! ah sir! Well, death's the end of all.\n",
      "9 I'll lay fourteen of my teeth, And yet, to my teeth be it spoken, I have but four She is not fourteen. How long is it now To Lammas-tide?\n"
     ]
    }
   ],
   "source": [
    "# Compute document similarity using LSA components\n",
    "similarity = np.asarray(np.asmatrix(X_train_lsa) * np.asmatrix(X_train_lsa).T)\n",
    "#Only taking the first 10 sentences\n",
    "sim_matrix=pd.DataFrame(similarity,index=X_train).iloc[0:10,0:10]\n",
    "#Making a plot\n",
    "ax = sns.heatmap(sim_matrix,yticklabels=range(10))\n",
    "plt.show()\n",
    "\n",
    "#Generating a key for the plot.\n",
    "print('Key:')\n",
    "for i in range(10):\n",
    "    print(i,sim_matrix.index[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Assess your models using cross-validation and determine whether one model performed better.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training</th>\n",
       "      <th>testing</th>\n",
       "      <th>cross_val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.498403</td>\n",
       "      <td>0.45 (+/- 0.17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>0.974414</td>\n",
       "      <td>0.466454</td>\n",
       "      <td>0.51 (+/- 0.07)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradient boosting</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.99 (+/- 0.01)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     training   testing    cross_val_acc\n",
       "random forest        0.989339  0.498403  0.45 (+/- 0.17)\n",
       "logistic regression  0.974414  0.466454  0.51 (+/- 0.07)\n",
       "gradient boosting    1.000000  1.000000  0.99 (+/- 0.01)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = ['random forest', 'logistic regression', 'gradient boosting']\n",
    "\n",
    "models = pd.DataFrame(index=order)\n",
    "\n",
    "models['training'] = training_all\n",
    "models['testing'] = testing_all\n",
    "models['cross_val_acc'] = cross_val_all\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like gradient boosting scored better across the board, though all of the models had pretty serious overfitting on the training set. Considering overfitting, the model that performed the best on the BOW features was the **gradient boosting** followed by **logistic regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Pick one of the models and try to increase accuracy by at least 5 percentage points.\n",
    "\n",
    "Let's try to improve the logistic regression model with the BOW features, since that one performed the best without overfitting. First, let's take another look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>Scene</th>\n",
       "      <th>Scene_Name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Line</th>\n",
       "      <th>parsed</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>be</th>\n",
       "      <th>and</th>\n",
       "      <th>the</th>\n",
       "      <th>...</th>\n",
       "      <th>issue</th>\n",
       "      <th>throw</th>\n",
       "      <th>sentence</th>\n",
       "      <th>citizen</th>\n",
       "      <th>canker'd</th>\n",
       "      <th>disturb</th>\n",
       "      <th>forfeit</th>\n",
       "      <th>Act_num</th>\n",
       "      <th>Scene_num</th>\n",
       "      <th>Speaker_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>Gregory, o' my word, we'll not carry coals.</td>\n",
       "      <td>(Gregory, ,, o, ', my, word, ,, we, 'll, not, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>No, for then we should be colliers.</td>\n",
       "      <td>(No, ,, for, then, we, should, be, colliers, .)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I mean, an we be in choler, we'll draw.</td>\n",
       "      <td>(I, mean, ,, an, we, be, in, choler, ,, we, 'l...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>Ay, while you live, draw your neck out o' the ...</td>\n",
       "      <td>(Ay, ,, while, you, live, ,, draw, your, neck,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I strike quickly, being moved.</td>\n",
       "      <td>(I, strike, quickly, ,, being, moved, .)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1009 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Act    Scene                 Scene_Name  Speaker  \\\n",
       "0  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "1  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "2  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "3  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "4  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "\n",
       "                                                Line  \\\n",
       "0        Gregory, o' my word, we'll not carry coals.   \n",
       "1                No, for then we should be colliers.   \n",
       "2            I mean, an we be in choler, we'll draw.   \n",
       "3  Ay, while you live, draw your neck out o' the ...   \n",
       "4                     I strike quickly, being moved.   \n",
       "\n",
       "                                              parsed  -PRON-  be  and  the  \\\n",
       "0  (Gregory, ,, o, ', my, word, ,, we, 'll, not, ...       2   0    0    0   \n",
       "1    (No, ,, for, then, we, should, be, colliers, .)       1   1    0    0   \n",
       "2  (I, mean, ,, an, we, be, in, choler, ,, we, 'l...       3   1    0    0   \n",
       "3  (Ay, ,, while, you, live, ,, draw, your, neck,...       2   0    0    1   \n",
       "4           (I, strike, quickly, ,, being, moved, .)       1   1    0    0   \n",
       "\n",
       "        ...        issue  throw  sentence  citizen  canker'd  disturb  \\\n",
       "0       ...            0      0         0        0         0        0   \n",
       "1       ...            0      0         0        0         0        0   \n",
       "2       ...            0      0         0        0         0        0   \n",
       "3       ...            0      0         0        0         0        0   \n",
       "4       ...            0      0         0        0         0        0   \n",
       "\n",
       "   forfeit  Act_num  Scene_num  Speaker_counts  \n",
       "0        0        1          1              20  \n",
       "1        0        1          1              15  \n",
       "2        0        1          1              20  \n",
       "3        0        1          1              15  \n",
       "4        0        1          1              20  \n",
       "\n",
       "[5 rows x 1009 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plus_bow_max.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <em>feature engineering</em>\n",
    "\n",
    "For features, we'll use Act and Scene. I'll add some more features too - first, word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostly now we're using the max df but i will add the values to plus_bow in case \n",
    "# something gets messed up, so i won't have to restart all the way from the beginning again\n",
    "df_plus_bow_max['word_count'] = len(df_plus_bow_max['parsed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plus_bow['word_count'] = len(df_plus_bow['parsed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also add a count of the unique parts of speech in each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_pos(Series):\n",
    "    \n",
    "    allpos = [token.pos_ for token in Series]\n",
    "        \n",
    "    return (len(set(allpos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plus_bow_max['unique_pos'] = df_plus_bow_max['parsed'].apply(unique_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plus_bow['unique_pos'] = df_plus_bow['parsed'].apply(unique_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and use word vectors on the sentence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30085 29678\n"
     ]
    }
   ],
   "source": [
    "# First I'm double checking that all or most of the words in the doc have vectors already.\n",
    "\n",
    "count = 0\n",
    "for token in complete_doc:\n",
    "    if token.has_vector:\n",
    "        count+=1\n",
    "    \n",
    "print(len(complete_doc), count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "# couldnt search complete_doc so rejoined the lines to search through w/ regular expression\n",
    "okay_again = ' '.join(all_the_lines)\n",
    "\n",
    "\n",
    "def get_vector(value):\n",
    "    \n",
    "    # get the location of the sentence in the nlp loaded text\n",
    "\n",
    "    target = re.compile(value)\n",
    "    \n",
    "    # find the target in complete_doc and return it as an itme\n",
    "    found = target.search(okay_again)\n",
    "    \n",
    "    if found != None:\n",
    "    \n",
    "        # beginning and end\n",
    "        start = found.start()\n",
    "        end = found.end()\n",
    "    \n",
    "        span = complete_doc[start:end]\n",
    "        \n",
    "        if span.has_vector:\n",
    "            return span.vector_norm\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df_plus_bow_max['vector'] = df_plus_bow_max['Line'].apply(get_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plus_bow['vector'] = df_plus_bow['Line'].apply(get_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>Scene</th>\n",
       "      <th>Scene_Name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Line</th>\n",
       "      <th>parsed</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>be</th>\n",
       "      <th>and</th>\n",
       "      <th>the</th>\n",
       "      <th>...</th>\n",
       "      <th>citizen</th>\n",
       "      <th>canker'd</th>\n",
       "      <th>disturb</th>\n",
       "      <th>forfeit</th>\n",
       "      <th>Act_num</th>\n",
       "      <th>Scene_num</th>\n",
       "      <th>Speaker_counts</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_pos</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>Gregory, o' my word, we'll not carry coals.</td>\n",
       "      <td>(Gregory, ,, o, ', my, word, ,, we, 'll, not, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>782</td>\n",
       "      <td>8</td>\n",
       "      <td>3.022147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>No, for then we should be colliers.</td>\n",
       "      <td>(No, ,, for, then, we, should, be, colliers, .)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>782</td>\n",
       "      <td>7</td>\n",
       "      <td>3.289926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I mean, an we be in choler, we'll draw.</td>\n",
       "      <td>(I, mean, ,, an, we, be, in, choler, ,, we, 'l...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>782</td>\n",
       "      <td>6</td>\n",
       "      <td>3.212513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>Ay, while you live, draw your neck out o' the ...</td>\n",
       "      <td>(Ay, ,, while, you, live, ,, draw, your, neck,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>782</td>\n",
       "      <td>9</td>\n",
       "      <td>3.014298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I strike quickly, being moved.</td>\n",
       "      <td>(I, strike, quickly, ,, being, moved, .)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>782</td>\n",
       "      <td>4</td>\n",
       "      <td>3.084016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1012 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Act    Scene                 Scene_Name  Speaker  \\\n",
       "0  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "1  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "2  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "3  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "4  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "\n",
       "                                                Line  \\\n",
       "0        Gregory, o' my word, we'll not carry coals.   \n",
       "1                No, for then we should be colliers.   \n",
       "2            I mean, an we be in choler, we'll draw.   \n",
       "3  Ay, while you live, draw your neck out o' the ...   \n",
       "4                     I strike quickly, being moved.   \n",
       "\n",
       "                                              parsed  -PRON-  be  and  the  \\\n",
       "0  (Gregory, ,, o, ', my, word, ,, we, 'll, not, ...       2   0    0    0   \n",
       "1    (No, ,, for, then, we, should, be, colliers, .)       1   1    0    0   \n",
       "2  (I, mean, ,, an, we, be, in, choler, ,, we, 'l...       3   1    0    0   \n",
       "3  (Ay, ,, while, you, live, ,, draw, your, neck,...       2   0    0    1   \n",
       "4           (I, strike, quickly, ,, being, moved, .)       1   1    0    0   \n",
       "\n",
       "     ...     citizen  canker'd  disturb  forfeit  Act_num  Scene_num  \\\n",
       "0    ...           0         0        0        0        1          1   \n",
       "1    ...           0         0        0        0        1          1   \n",
       "2    ...           0         0        0        0        1          1   \n",
       "3    ...           0         0        0        0        1          1   \n",
       "4    ...           0         0        0        0        1          1   \n",
       "\n",
       "   Speaker_counts  word_count  unique_pos    vector  \n",
       "0              20         782           8  3.022147  \n",
       "1              15         782           7  3.289926  \n",
       "2              20         782           6  3.212513  \n",
       "3              15         782           9  3.014298  \n",
       "4              20         782           4  3.084016  \n",
       "\n",
       "[5 rows x 1012 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plus_bow_max.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the correlation matrix and drop highly correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_m = df_plus_bow_max.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dream', 'sound', 'year', \"o'er\", 'straight', 'silver', 'pretty', 'bite', 'finger', 'fourteen', 'shape', 'nature', 'lark', 'churchyard', 'pain', 'depart', 'quoth', 'asleep', 'fain', 'hare', 'hoar', 'cruel', 'cheer', 'big', 'small', 'womb', 'stain', 'number', 'backward', 'lammas', 'susan', 'dug', 'jule', 'mab', 'nose', 'gallop', 'endure', 'passion', 'appear', 'raven', 'methinks', 'needy', \"hear'st\", 'shroud', 'awake', 'scene', 'mutiny', 'neck', 'partisan', 'throw']\n"
     ]
    }
   ],
   "source": [
    "flds = corr_m.columns.values\n",
    "\n",
    "to_drop = []\n",
    "\n",
    "for i in range(corr_m.shape[1]):\n",
    "    for j in range(i+1, corr_m.shape[1]):\n",
    "        if corr_m.iloc[i,j] > 0.755:\n",
    "            #print(flds[i], ' ', flds[j], ' ', corr_m.iloc[i,j])\n",
    "        \n",
    "            if flds[i] not in to_drop:\n",
    "                to_drop.append(flds[i])\n",
    "\n",
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dream', 'year', 'straight', 'pretty', 'finger', 'shape', 'lark', 'pain', 'quoth', 'fain', 'hoar', 'cheer', 'small', 'stain', 'backward', 'susan', 'jule', 'nose', 'endure', 'appear', 'methinks', \"hear'st\", 'awake', 'mutiny', 'partisan']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "even = range(len(to_drop)-1, 0,-2)\n",
    "\n",
    "for i in even:\n",
    "    to_drop.remove(to_drop[i])\n",
    "print(to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plus_bow_max.drop(to_drop,1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>Scene</th>\n",
       "      <th>Scene_Name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Line</th>\n",
       "      <th>parsed</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>be</th>\n",
       "      <th>and</th>\n",
       "      <th>the</th>\n",
       "      <th>...</th>\n",
       "      <th>citizen</th>\n",
       "      <th>canker'd</th>\n",
       "      <th>disturb</th>\n",
       "      <th>forfeit</th>\n",
       "      <th>Act_num</th>\n",
       "      <th>Scene_num</th>\n",
       "      <th>Speaker_counts</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_pos</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>Gregory, o' my word, we'll not carry coals.</td>\n",
       "      <td>(Gregory, ,, o, ', my, word, ,, we, 'll, not, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>782</td>\n",
       "      <td>8</td>\n",
       "      <td>3.022147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>No, for then we should be colliers.</td>\n",
       "      <td>(No, ,, for, then, we, should, be, colliers, .)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>782</td>\n",
       "      <td>7</td>\n",
       "      <td>3.289926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I mean, an we be in choler, we'll draw.</td>\n",
       "      <td>(I, mean, ,, an, we, be, in, choler, ,, we, 'l...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>782</td>\n",
       "      <td>6</td>\n",
       "      <td>3.212513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>Ay, while you live, draw your neck out o' the ...</td>\n",
       "      <td>(Ay, ,, while, you, live, ,, draw, your, neck,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>782</td>\n",
       "      <td>9</td>\n",
       "      <td>3.014298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I strike quickly, being moved.</td>\n",
       "      <td>(I, strike, quickly, ,, being, moved, .)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>782</td>\n",
       "      <td>4</td>\n",
       "      <td>3.084016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 987 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Act    Scene                 Scene_Name  Speaker  \\\n",
       "0  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "1  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "2  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "3  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "4  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "\n",
       "                                                Line  \\\n",
       "0        Gregory, o' my word, we'll not carry coals.   \n",
       "1                No, for then we should be colliers.   \n",
       "2            I mean, an we be in choler, we'll draw.   \n",
       "3  Ay, while you live, draw your neck out o' the ...   \n",
       "4                     I strike quickly, being moved.   \n",
       "\n",
       "                                              parsed  -PRON-  be  and  the  \\\n",
       "0  (Gregory, ,, o, ', my, word, ,, we, 'll, not, ...       2   0    0    0   \n",
       "1    (No, ,, for, then, we, should, be, colliers, .)       1   1    0    0   \n",
       "2  (I, mean, ,, an, we, be, in, choler, ,, we, 'l...       3   1    0    0   \n",
       "3  (Ay, ,, while, you, live, ,, draw, your, neck,...       2   0    0    1   \n",
       "4           (I, strike, quickly, ,, being, moved, .)       1   1    0    0   \n",
       "\n",
       "     ...     citizen  canker'd  disturb  forfeit  Act_num  Scene_num  \\\n",
       "0    ...           0         0        0        0        1          1   \n",
       "1    ...           0         0        0        0        1          1   \n",
       "2    ...           0         0        0        0        1          1   \n",
       "3    ...           0         0        0        0        1          1   \n",
       "4    ...           0         0        0        0        1          1   \n",
       "\n",
       "   Speaker_counts  word_count  unique_pos    vector  \n",
       "0              20         782           8  3.022147  \n",
       "1              15         782           7  3.289926  \n",
       "2              20         782           6  3.212513  \n",
       "3              15         782           9  3.014298  \n",
       "4              20         782           4  3.084016  \n",
       "\n",
       "[5 rows x 987 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plus_bow_max.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping some more features - keeping just the 90 most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df_plus_bow_max.iloc[:, 8:962]\n",
    "\n",
    "all_w = words.columns.values\n",
    "\n",
    "array_to_keep = words.sum().head(150)\n",
    "array_to_drop = []\n",
    "\n",
    "for value in all_w:\n",
    "    if value not in array_to_keep.index.values:\n",
    "        array_to_drop.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plus_bow_max.drop(array_to_drop,1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>Scene</th>\n",
       "      <th>Scene_Name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Line</th>\n",
       "      <th>parsed</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>be</th>\n",
       "      <th>and</th>\n",
       "      <th>the</th>\n",
       "      <th>...</th>\n",
       "      <th>citizen</th>\n",
       "      <th>canker'd</th>\n",
       "      <th>disturb</th>\n",
       "      <th>forfeit</th>\n",
       "      <th>Act_num</th>\n",
       "      <th>Scene_num</th>\n",
       "      <th>Speaker_counts</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_pos</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>Gregory, o' my word, we'll not carry coals.</td>\n",
       "      <td>(Gregory, ,, o, ', my, word, ,, we, 'll, not, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>782</td>\n",
       "      <td>8</td>\n",
       "      <td>3.022147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>No, for then we should be colliers.</td>\n",
       "      <td>(No, ,, for, then, we, should, be, colliers, .)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>782</td>\n",
       "      <td>7</td>\n",
       "      <td>3.289926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I mean, an we be in choler, we'll draw.</td>\n",
       "      <td>(I, mean, ,, an, we, be, in, choler, ,, we, 'l...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>782</td>\n",
       "      <td>6</td>\n",
       "      <td>3.212513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>Ay, while you live, draw your neck out o' the ...</td>\n",
       "      <td>(Ay, ,, while, you, live, ,, draw, your, neck,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>782</td>\n",
       "      <td>9</td>\n",
       "      <td>3.014298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACT I</td>\n",
       "      <td>SCENE I</td>\n",
       "      <td>Verona. A public place.</td>\n",
       "      <td>SAMPSON</td>\n",
       "      <td>I strike quickly, being moved.</td>\n",
       "      <td>(I, strike, quickly, ,, being, moved, .)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>782</td>\n",
       "      <td>4</td>\n",
       "      <td>3.084016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Act    Scene                 Scene_Name  Speaker  \\\n",
       "0  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "1  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "2  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "3  ACT I  SCENE I    Verona. A public place.  GREGORY   \n",
       "4  ACT I  SCENE I    Verona. A public place.  SAMPSON   \n",
       "\n",
       "                                                Line  \\\n",
       "0        Gregory, o' my word, we'll not carry coals.   \n",
       "1                No, for then we should be colliers.   \n",
       "2            I mean, an we be in choler, we'll draw.   \n",
       "3  Ay, while you live, draw your neck out o' the ...   \n",
       "4                     I strike quickly, being moved.   \n",
       "\n",
       "                                              parsed  -PRON-  be  and  the  \\\n",
       "0  (Gregory, ,, o, ', my, word, ,, we, 'll, not, ...       2   0    0    0   \n",
       "1    (No, ,, for, then, we, should, be, colliers, .)       1   1    0    0   \n",
       "2  (I, mean, ,, an, we, be, in, choler, ,, we, 'l...       3   1    0    0   \n",
       "3  (Ay, ,, while, you, live, ,, draw, your, neck,...       2   0    0    1   \n",
       "4           (I, strike, quickly, ,, being, moved, .)       1   1    0    0   \n",
       "\n",
       "     ...     citizen  canker'd  disturb  forfeit  Act_num  Scene_num  \\\n",
       "0    ...           0         0        0        0        1          1   \n",
       "1    ...           0         0        0        0        1          1   \n",
       "2    ...           0         0        0        0        1          1   \n",
       "3    ...           0         0        0        0        1          1   \n",
       "4    ...           0         0        0        0        1          1   \n",
       "\n",
       "   Speaker_counts  word_count  unique_pos    vector  \n",
       "0              20         782           8  3.022147  \n",
       "1              15         782           7  3.289926  \n",
       "2              20         782           6  3.212513  \n",
       "3              15         782           9  3.014298  \n",
       "4              20         782           4  3.084016  \n",
       "\n",
       "[5 rows x 183 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plus_bow_max.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <em>fitting the logistic model</em>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. getting the testing and training samples\n",
    "\n",
    "Y_new_f = df_plus_bow_max['Speaker']\n",
    "X_new_f = df_plus_bow_max.drop(['Act','Scene', 'Scene_Name', 'Speaker', 'Line', 'parsed'], 1)\n",
    "\n",
    "X_train_new_f, X_test_new_f, y_train_new_f, y_test_new_f = train_test_split(X_new_f, \n",
    "                                                    Y_new_f,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(469, 177) (469,)\n",
      "Training set score: 0.9317697228144989\n",
      "\n",
      "Test set score: 0.5271565495207667\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_new_f, y_train_new_f)\n",
    "print(X_train_new_f.shape, y_train_new_f.shape)\n",
    "print('Training set score:', lr.score(X_train_new_f, y_train_new_f))\n",
    "print('\\nTest set score:', lr.score(X_test_new_f, y_test_new_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "validate_lr2 = cross_val_score(lr, X_test_new_f, y_test_new_f, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.56 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (validate_lr2.mean(), validate_lr2.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the data to run PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train_new_f)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "train_scale = scaler.transform(X_train_new_f)\n",
    "test_scale = scaler.transform(X_test_new_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting PCA threshold to a % (so the components explain that % of the variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Make an instance of the Model\n",
    "pca = PCA(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "# fit it on the training set\n",
    "\n",
    "pca.fit(train_scale)\n",
    "\n",
    "print(pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transofmr the training and test sets\n",
    "\n",
    "train_scale = pca.transform(train_scale)\n",
    "test_scale = pca.transform(test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(469, 111) (469,)\n",
      "Training set score: 0.9019189765458422\n",
      "\n",
      "Test set score: 0.4217252396166134\n"
     ]
    }
   ],
   "source": [
    "lr.fit(train_scale, y_train_new_f)\n",
    "\n",
    "print(train_scale.shape, y_train_new_f.shape)\n",
    "print('Training set score:', lr.score(train_scale, y_train_new_f))\n",
    "print('\\nTest set score:', lr.score(test_scale, y_test_new_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "validate_lr3 = cross_val_score(lr, test_scale, y_test_new_f, cv=5)\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (validate_lr3.mean(), validate_lr3.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
